{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1040675",
   "metadata": {},
   "source": [
    "# Get some toy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e10ba0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import importlib\n",
    "from tensorflow.keras.utils import plot_model\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6acdeec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ae1c7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('..\\\\Datasets\\\\Kabetogama\\\\MIX_dataset.csv', delimiter=',')\n",
    "#process the data to get the number of minutes since start:\n",
    "start = datetime.datetime.strptime(data['DateTime'][0], \"%m/%d/%Y %H:%M\")\n",
    "\n",
    "data['DateTime'] = [(datetime.datetime.strptime(el, \"%m/%d/%Y %H:%M\")-start).total_seconds()/60\n",
    "                    for el in data['DateTime']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "43a0d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize all data:\n",
    "data = (data-data.mean())/data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0744f2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>ELISA_MC+ANA+SXT</th>\n",
       "      <th>TP_mgL_LAG</th>\n",
       "      <th>Plank_mcyE_cp100mL_LAG</th>\n",
       "      <th>anaC_cp100mL_LAG</th>\n",
       "      <th>sxtA_cp100mL_LAG</th>\n",
       "      <th>WindDirInst_deg</th>\n",
       "      <th>LkLevelChg14day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.903046</td>\n",
       "      <td>-0.583794</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>-0.259385</td>\n",
       "      <td>-0.399740</td>\n",
       "      <td>-0.493282</td>\n",
       "      <td>1.639099</td>\n",
       "      <td>1.978509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.902916</td>\n",
       "      <td>-0.583794</td>\n",
       "      <td>0.083683</td>\n",
       "      <td>-0.259700</td>\n",
       "      <td>-0.373148</td>\n",
       "      <td>-0.485208</td>\n",
       "      <td>1.186809</td>\n",
       "      <td>1.468409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.865660</td>\n",
       "      <td>-0.583794</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>-0.252598</td>\n",
       "      <td>-0.345243</td>\n",
       "      <td>-0.489533</td>\n",
       "      <td>0.463145</td>\n",
       "      <td>-1.830240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.865530</td>\n",
       "      <td>-0.583794</td>\n",
       "      <td>0.769609</td>\n",
       "      <td>-0.259700</td>\n",
       "      <td>-0.322262</td>\n",
       "      <td>-0.459257</td>\n",
       "      <td>-0.260519</td>\n",
       "      <td>-1.388153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.865389</td>\n",
       "      <td>-0.293376</td>\n",
       "      <td>0.906794</td>\n",
       "      <td>-0.259700</td>\n",
       "      <td>-0.333753</td>\n",
       "      <td>-0.347520</td>\n",
       "      <td>-1.617389</td>\n",
       "      <td>-0.214922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DateTime  ELISA_MC+ANA+SXT  TP_mgL_LAG  Plank_mcyE_cp100mL_LAG  \\\n",
       "0 -0.903046         -0.583794   -0.053502               -0.259385   \n",
       "1 -0.902916         -0.583794    0.083683               -0.259700   \n",
       "2 -0.865660         -0.583794    0.495238               -0.252598   \n",
       "3 -0.865530         -0.583794    0.769609               -0.259700   \n",
       "4 -0.865389         -0.293376    0.906794               -0.259700   \n",
       "\n",
       "   anaC_cp100mL_LAG  sxtA_cp100mL_LAG  WindDirInst_deg  LkLevelChg14day  \n",
       "0         -0.399740         -0.493282         1.639099         1.978509  \n",
       "1         -0.373148         -0.485208         1.186809         1.468409  \n",
       "2         -0.345243         -0.489533         0.463145        -1.830240  \n",
       "3         -0.322262         -0.459257        -0.260519        -1.388153  \n",
       "4         -0.333753         -0.347520        -1.617389        -0.214922  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "47ed2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a transformer that only predict 1D time series 1 step in advance,using the 10 previous measures \n",
    "#(this is not necessary, but allows to process batchs of data):\n",
    "import transformers as tr\n",
    "importlib.reload(tr)\n",
    "input_shape = (10,2)\n",
    "inputs = layers.Input(input_shape)\n",
    "#n_inputs = layers.BatchNormalization()(inputs)\n",
    "trans = tr.transformer(input_shape=input_shape,\n",
    "    head_size=6,\n",
    "    num_heads=6,\n",
    "    ff_dim=20,\n",
    "    num_transformer_blocks=6,\n",
    "    mlp_units=[10,10,10],\n",
    "    n_out = 1,\n",
    "    dropout=0.2,\n",
    "    mlp_dropout=0.3\n",
    ")\n",
    "#out = trans(n_inputs)\n",
    "model = trans#Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cfcf464f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 10, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_36 (MultiH (None, 10, 2)        398         input_11[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 10, 2)        0           multi_head_attention_36[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_72 (LayerNo (None, 10, 2)        4           dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_72 (TFOpLa (None, 10, 2)        0           layer_normalization_72[0][0]     \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 10, 20)       60          tf.__operators__.add_72[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 10, 20)       0           conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 10, 2)        42          dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_73 (LayerNo (None, 10, 2)        4           conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_73 (TFOpLa (None, 10, 2)        0           layer_normalization_73[0][0]     \n",
      "                                                                 tf.__operators__.add_72[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_37 (MultiH (None, 10, 2)        398         tf.__operators__.add_73[0][0]    \n",
      "                                                                 tf.__operators__.add_73[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 10, 2)        0           multi_head_attention_37[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_74 (LayerNo (None, 10, 2)        4           dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_74 (TFOpLa (None, 10, 2)        0           layer_normalization_74[0][0]     \n",
      "                                                                 tf.__operators__.add_73[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 10, 20)       60          tf.__operators__.add_74[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 10, 20)       0           conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 10, 2)        42          dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_75 (LayerNo (None, 10, 2)        4           conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_75 (TFOpLa (None, 10, 2)        0           layer_normalization_75[0][0]     \n",
      "                                                                 tf.__operators__.add_74[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_38 (MultiH (None, 10, 2)        398         tf.__operators__.add_75[0][0]    \n",
      "                                                                 tf.__operators__.add_75[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 10, 2)        0           multi_head_attention_38[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_76 (LayerNo (None, 10, 2)        4           dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_76 (TFOpLa (None, 10, 2)        0           layer_normalization_76[0][0]     \n",
      "                                                                 tf.__operators__.add_75[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 10, 20)       60          tf.__operators__.add_76[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 10, 20)       0           conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 10, 2)        42          dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_77 (LayerNo (None, 10, 2)        4           conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_77 (TFOpLa (None, 10, 2)        0           layer_normalization_77[0][0]     \n",
      "                                                                 tf.__operators__.add_76[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_39 (MultiH (None, 10, 2)        398         tf.__operators__.add_77[0][0]    \n",
      "                                                                 tf.__operators__.add_77[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 10, 2)        0           multi_head_attention_39[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_78 (LayerNo (None, 10, 2)        4           dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_78 (TFOpLa (None, 10, 2)        0           layer_normalization_78[0][0]     \n",
      "                                                                 tf.__operators__.add_77[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 10, 20)       60          tf.__operators__.add_78[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 10, 20)       0           conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 10, 2)        42          dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_79 (LayerNo (None, 10, 2)        4           conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_79 (TFOpLa (None, 10, 2)        0           layer_normalization_79[0][0]     \n",
      "                                                                 tf.__operators__.add_78[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_40 (MultiH (None, 10, 2)        398         tf.__operators__.add_79[0][0]    \n",
      "                                                                 tf.__operators__.add_79[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 10, 2)        0           multi_head_attention_40[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_80 (LayerNo (None, 10, 2)        4           dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_80 (TFOpLa (None, 10, 2)        0           layer_normalization_80[0][0]     \n",
      "                                                                 tf.__operators__.add_79[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 10, 20)       60          tf.__operators__.add_80[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 10, 20)       0           conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 10, 2)        42          dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_81 (LayerNo (None, 10, 2)        4           conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_81 (TFOpLa (None, 10, 2)        0           layer_normalization_81[0][0]     \n",
      "                                                                 tf.__operators__.add_80[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_41 (MultiH (None, 10, 2)        398         tf.__operators__.add_81[0][0]    \n",
      "                                                                 tf.__operators__.add_81[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 10, 2)        0           multi_head_attention_41[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_82 (LayerNo (None, 10, 2)        4           dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_82 (TFOpLa (None, 10, 2)        0           layer_normalization_82[0][0]     \n",
      "                                                                 tf.__operators__.add_81[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 10, 20)       60          tf.__operators__.add_82[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 10, 20)       0           conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 10, 2)        42          dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_83 (LayerNo (None, 10, 2)        4           conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_83 (TFOpLa (None, 10, 2)        0           layer_normalization_83[0][0]     \n",
      "                                                                 tf.__operators__.add_82[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 10)           0           tf.__operators__.add_83[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10)           110         global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 10)           0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 10)           110         dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 10)           0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 10)           110         dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 10)           0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            11          dropout_104[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,389\n",
      "Trainable params: 3,389\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#plot_model(model, show_shapes=True, show_layer_names=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1457d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def input_pipeline(ds):\n",
    "    ds = ds.shuffle(1000)\n",
    "    ds = ds.batch(10)\n",
    "    return ds\n",
    "#select the time series of interest:\n",
    "serie = data[['DateTime','ELISA_MC+ANA+SXT']]\n",
    "n_sample = 10\n",
    "n_outputs = 1\n",
    "context = [serie.iloc[i:n_sample+i][:].to_numpy() for i in range(len(serie)-n_sample-n_outputs+1)]\n",
    "if n_outputs>1:\n",
    "    target = [serie.iloc[n_sample+i:n_sample+i+n_outputs-1][:].to_numpy()    for i in range(len(serie)-n_sample-n_outputs+1)]\n",
    "else:\n",
    "    target = [serie.iloc[n_sample+i][:].to_numpy()    for i in range(len(serie)-n_sample-n_outputs+1)]\n",
    "    #use the first half as training:\n",
    "dt = tf.data.Dataset.from_tensor_slices((context[0:20],target[0:20]))\n",
    "dt = input_pipeline(dt)\n",
    "dv = tf.data.Dataset.from_tensor_slices((context[20:],target[20:]))\n",
    "dv = input_pipeline(dv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bdb5df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',\n",
    "              loss = tf.keras.metrics.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5821a8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12524), started 0:21:12 ago. (Use '!kill 12524' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8fa4f20233a30559\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8fa4f20233a30559\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "savebest = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=2000,\n",
    "    restore_best_weights=True)\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "648128c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26544/3321559038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'logs/norm'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msavebest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1214\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1215\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_dir = 'logs/norm'\n",
    "h = model.fit(dt,validation_data = dv,epochs=100000,verbose=0,callbacks = [savebest,keras.callbacks.TensorBoard(log_dir=log_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b3c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e68dfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e84dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
