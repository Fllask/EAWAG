{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import os\n",
    "import sklearn.model_selection\n",
    "import tensorboard\n",
    "import pickle\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c9ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataset:\n",
    "#address of the base folder:\n",
    "base = \"R:\\\\3.Masters_projects\\\\2021_Dominic_Rebindaine\\\\ROI\"\n",
    "#extract the name from the file name:\n",
    "name_l =[]\n",
    "path_l = []\n",
    "for fname in os.listdir(base):\n",
    "    pathto = os.path.join(base,fname)\n",
    "    \n",
    "    if os.path.isdir(pathto):\n",
    "        path_l.append(pathto)\n",
    "        split = fname.split(sep='_')\n",
    "        if len(split)>2:\n",
    "            name = split[1]\n",
    "            name_l.append(name)\n",
    "label_name, label = np.unique(name_l,return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef86a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the input data:\n",
    "image_size = 100 \n",
    "size = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aee561f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the images and find their label\n",
    "def data_opener(name):\n",
    "    img = tf.io.decode_png(tf.io.read_file(name))\n",
    "    X = tf.image.resize(img,(size,size))\n",
    "    Xn = tf.image.per_image_standardization(X)\n",
    "    part = tf.strings.split(name,os.sep)\n",
    "    fname = part[4]\n",
    "    fpart = tf.strings.split(fname,'_')\n",
    "    if len(fpart)<2:\n",
    "        y = -1\n",
    "    else:\n",
    "        el_label = fpart[1]\n",
    "        y = -1\n",
    "        for idx, label in enumerate(label_name):\n",
    "            if label == el_label:\n",
    "                y = idx\n",
    "    data = (Xn,y)\n",
    "    return data\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def data_aug(img,label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    rnd = np.random.randint(4)\n",
    "    img = tf.image.rot90(img,k=rnd)\n",
    "    img = tf.image.random_hue(img,0.1)\n",
    "    #stddev = tf.random.uniform(shape=[1],maxval=0.05)\n",
    "    #img+= tf.random.normal((size,size,3),stddev=stddev)\n",
    "    return (img,label)\n",
    "\n",
    "\n",
    "def input_pipeline(ds, augmentation = False):\n",
    "    ds = ds.shuffle(10000)\n",
    "    ds = ds.map(data_opener)\n",
    "    #filter out the unlabeled elements\n",
    "    ds = ds.filter(lambda X,y: y>=0)\n",
    "    if augmentation:\n",
    "        ds = ds.map(data_aug)\n",
    "    ds = ds.batch(32)\n",
    "    ds = ds.prefetch(10)\n",
    "    return ds\n",
    "def destand(img_n, perc = 1,epsilon = 0.0001):\n",
    "    pl,ph = np.percentile(img_n, [perc,100-perc])\n",
    "    img = np.array((img_n-pl)/(epsilon+ph-pl))\n",
    "    img[img>1]=1\n",
    "    img[img<0]=0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d50fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = tf.data.Dataset.list_files('R:\\\\3.Masters_projects\\\\2021_Dominic_Rebindaine\\\\ROI\\\\*\\\\*\\\\*.png')\n",
    "#split the dataset now, as the loading of the image would need too long to use the list function\n",
    "train, val = sklearn.model_selection.train_test_split(list(file_names),test_size= 0.2)\n",
    "dt = tf.data.Dataset.from_tensor_slices(train)\n",
    "dv = tf.data.Dataset.from_tensor_slices(val)\n",
    "\n",
    "dt = input_pipeline(dt,augmentation = True)\n",
    "dv = input_pipeline(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc93cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first test\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "patch_size = 10  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [512, 256]  # Size of the dense layers of the final classifier\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6072fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd test\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "patch_size = 10  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 10\n",
    "mlp_head_units = [720, 360]  # Size of the dense layers of the final classifier\n",
    "dropout_rate = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737192c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de4fad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80498d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8416/615845890.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "data = list(dt.take(1))\n",
    "image = data[0][0][0].numpy()\n",
    "plt.imshow(destand(image))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([destand(image)]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy())\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66d5cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7687db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=(image_size,image_size,3))\n",
    "    # Augment data.\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.8)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=dropout_rate)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(len(label_name))(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "626552ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_classifier = create_vit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49ddf542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patches_9 (Patches)             (None, None, 300)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder_3 (PatchEncoder)  (None, 100, 64)      25664       patches_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_51 (LayerNo (None, 100, 64)      128         patch_encoder_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_24 (MultiH (None, 100, 64)      66368       layer_normalization_51[0][0]     \n",
      "                                                                 layer_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 100, 64)      0           multi_head_attention_24[0][0]    \n",
      "                                                                 patch_encoder_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_52 (LayerNo (None, 100, 64)      128         add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 100, 128)     8320        layer_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 100, 128)     0           dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 100, 64)      8256        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 100, 64)      0           dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 100, 64)      0           dropout_58[0][0]                 \n",
      "                                                                 add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_53 (LayerNo (None, 100, 64)      128         add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_25 (MultiH (None, 100, 64)      66368       layer_normalization_53[0][0]     \n",
      "                                                                 layer_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 100, 64)      0           multi_head_attention_25[0][0]    \n",
      "                                                                 add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_54 (LayerNo (None, 100, 64)      128         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 100, 128)     8320        layer_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 100, 128)     0           dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 100, 64)      8256        dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 100, 64)      0           dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 100, 64)      0           dropout_60[0][0]                 \n",
      "                                                                 add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_55 (LayerNo (None, 100, 64)      128         add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_26 (MultiH (None, 100, 64)      66368       layer_normalization_55[0][0]     \n",
      "                                                                 layer_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 100, 64)      0           multi_head_attention_26[0][0]    \n",
      "                                                                 add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_56 (LayerNo (None, 100, 64)      128         add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 100, 128)     8320        layer_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 100, 128)     0           dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 100, 64)      8256        dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 100, 64)      0           dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 100, 64)      0           dropout_62[0][0]                 \n",
      "                                                                 add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_57 (LayerNo (None, 100, 64)      128         add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_27 (MultiH (None, 100, 64)      66368       layer_normalization_57[0][0]     \n",
      "                                                                 layer_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 100, 64)      0           multi_head_attention_27[0][0]    \n",
      "                                                                 add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_58 (LayerNo (None, 100, 64)      128         add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 100, 128)     8320        layer_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 100, 128)     0           dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 100, 64)      8256        dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 100, 64)      0           dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 100, 64)      0           dropout_64[0][0]                 \n",
      "                                                                 add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_59 (LayerNo (None, 100, 64)      128         add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_28 (MultiH (None, 100, 64)      66368       layer_normalization_59[0][0]     \n",
      "                                                                 layer_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 100, 64)      0           multi_head_attention_28[0][0]    \n",
      "                                                                 add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_60 (LayerNo (None, 100, 64)      128         add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 100, 128)     8320        layer_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 100, 128)     0           dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 100, 64)      8256        dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 100, 64)      0           dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 100, 64)      0           dropout_66[0][0]                 \n",
      "                                                                 add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_61 (LayerNo (None, 100, 64)      128         add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_29 (MultiH (None, 100, 64)      66368       layer_normalization_61[0][0]     \n",
      "                                                                 layer_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 100, 64)      0           multi_head_attention_29[0][0]    \n",
      "                                                                 add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_62 (LayerNo (None, 100, 64)      128         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 100, 128)     8320        layer_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 100, 128)     0           dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 100, 64)      8256        dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 100, 64)      0           dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 100, 64)      0           dropout_68[0][0]                 \n",
      "                                                                 add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_63 (LayerNo (None, 100, 64)      128         add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_30 (MultiH (None, 100, 64)      66368       layer_normalization_63[0][0]     \n",
      "                                                                 layer_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 100, 64)      0           multi_head_attention_30[0][0]    \n",
      "                                                                 add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_64 (LayerNo (None, 100, 64)      128         add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 100, 128)     8320        layer_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 100, 128)     0           dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 100, 64)      8256        dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 100, 64)      0           dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 100, 64)      0           dropout_70[0][0]                 \n",
      "                                                                 add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_65 (LayerNo (None, 100, 64)      128         add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_31 (MultiH (None, 100, 64)      66368       layer_normalization_65[0][0]     \n",
      "                                                                 layer_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 100, 64)      0           multi_head_attention_31[0][0]    \n",
      "                                                                 add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_66 (LayerNo (None, 100, 64)      128         add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 100, 128)     8320        layer_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 100, 128)     0           dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 100, 64)      8256        dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 100, 64)      0           dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 100, 64)      0           dropout_72[0][0]                 \n",
      "                                                                 add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_67 (LayerNo (None, 100, 64)      128         add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_32 (MultiH (None, 100, 64)      66368       layer_normalization_67[0][0]     \n",
      "                                                                 layer_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 100, 64)      0           multi_head_attention_32[0][0]    \n",
      "                                                                 add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_68 (LayerNo (None, 100, 64)      128         add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 100, 128)     8320        layer_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 100, 128)     0           dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 100, 64)      8256        dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 100, 64)      0           dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 100, 64)      0           dropout_74[0][0]                 \n",
      "                                                                 add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_69 (LayerNo (None, 100, 64)      128         add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_33 (MultiH (None, 100, 64)      66368       layer_normalization_69[0][0]     \n",
      "                                                                 layer_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 100, 64)      0           multi_head_attention_33[0][0]    \n",
      "                                                                 add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_70 (LayerNo (None, 100, 64)      128         add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 100, 128)     8320        layer_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 100, 128)     0           dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 100, 64)      8256        dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 100, 64)      0           dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 100, 64)      0           dropout_76[0][0]                 \n",
      "                                                                 add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_71 (LayerNo (None, 100, 64)      128         add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 6400)         0           layer_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 6400)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 720)          4608720     dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 720)          0           dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 360)          259560      dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 360)          0           dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 11)           3971        dropout_79[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,730,043\n",
      "Trainable params: 5,730,043\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vit_classifier.summary()\n",
    "vit_classifier.compile(optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay),\n",
    "                       loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c5e54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "savebest = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=7,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed0a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8431c3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e450ae999c80d52f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e450ae999c80d52f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "019367e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Patches has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/50\n",
      "265/265 [==============================] - 255s 911ms/step - loss: 2.9487 - val_loss: 1.7796\n",
      "Epoch 2/50\n",
      "265/265 [==============================] - 238s 895ms/step - loss: 1.8555 - val_loss: 1.8600\n",
      "Epoch 3/50\n",
      "265/265 [==============================] - 233s 878ms/step - loss: 1.7222 - val_loss: 1.5105\n",
      "Epoch 4/50\n",
      "265/265 [==============================] - 234s 879ms/step - loss: 1.6032 - val_loss: 1.5568\n",
      "Epoch 5/50\n",
      "265/265 [==============================] - 237s 889ms/step - loss: 1.5317 - val_loss: 1.4142\n",
      "Epoch 6/50\n",
      "265/265 [==============================] - 235s 881ms/step - loss: 1.4599 - val_loss: 1.3612\n",
      "Epoch 7/50\n",
      "265/265 [==============================] - 226s 849ms/step - loss: 1.4006 - val_loss: 1.3475\n",
      "Epoch 8/50\n",
      "265/265 [==============================] - 230s 869ms/step - loss: 1.3677 - val_loss: 1.3598\n",
      "Epoch 9/50\n",
      "265/265 [==============================] - 239s 904ms/step - loss: 1.3205 - val_loss: 1.2530\n",
      "Epoch 10/50\n",
      "265/265 [==============================] - 239s 899ms/step - loss: 1.2668 - val_loss: 1.1626\n",
      "Epoch 11/50\n",
      "265/265 [==============================] - 236s 884ms/step - loss: 1.2252 - val_loss: 1.1648\n",
      "Epoch 12/50\n",
      "265/265 [==============================] - 242s 907ms/step - loss: 1.2322 - val_loss: 1.1700\n",
      "Epoch 13/50\n",
      "265/265 [==============================] - 250s 937ms/step - loss: 1.1770 - val_loss: 1.1310\n",
      "Epoch 14/50\n",
      "265/265 [==============================] - 310s 1s/step - loss: 1.1472 - val_loss: 1.0872\n",
      "Epoch 15/50\n",
      "265/265 [==============================] - 375s 1s/step - loss: 1.1286 - val_loss: 0.9787\n",
      "Epoch 16/50\n",
      "265/265 [==============================] - 647s 2s/step - loss: 1.0732 - val_loss: 1.0167\n",
      "Epoch 17/50\n",
      "265/265 [==============================] - 213s 797ms/step - loss: 1.0222 - val_loss: 0.9428\n",
      "Epoch 18/50\n",
      "265/265 [==============================] - 197s 741ms/step - loss: 0.9680 - val_loss: 0.8307\n",
      "Epoch 19/50\n",
      "265/265 [==============================] - 185s 692ms/step - loss: 0.9056 - val_loss: 0.8019\n",
      "Epoch 20/50\n",
      "265/265 [==============================] - 234s 879ms/step - loss: 0.8633 - val_loss: 0.7465\n",
      "Epoch 21/50\n",
      "265/265 [==============================] - 373s 1s/step - loss: 0.8094 - val_loss: 0.7982\n",
      "Epoch 22/50\n",
      "265/265 [==============================] - 798s 3s/step - loss: 0.7851 - val_loss: 0.6245\n",
      "Epoch 23/50\n",
      "265/265 [==============================] - 797s 3s/step - loss: 0.7398 - val_loss: 0.6137\n",
      "Epoch 24/50\n",
      "265/265 [==============================] - 795s 3s/step - loss: 0.7114 - val_loss: 0.5742\n",
      "Epoch 25/50\n",
      "265/265 [==============================] - 798s 3s/step - loss: 0.6631 - val_loss: 0.5185\n",
      "Epoch 26/50\n",
      "265/265 [==============================] - 793s 3s/step - loss: 0.6482 - val_loss: 0.5553\n",
      "Epoch 27/50\n",
      "265/265 [==============================] - 799s 3s/step - loss: 0.5966 - val_loss: 0.4953\n",
      "Epoch 28/50\n",
      "265/265 [==============================] - 597s 2s/step - loss: 0.5900 - val_loss: 0.5429\n",
      "Epoch 29/50\n",
      "265/265 [==============================] - 321s 1s/step - loss: 0.5635 - val_loss: 0.5416\n",
      "Epoch 30/50\n",
      "265/265 [==============================] - 468s 2s/step - loss: 0.5675 - val_loss: 0.4691\n",
      "Epoch 31/50\n",
      "265/265 [==============================] - 792s 3s/step - loss: 0.5378 - val_loss: 0.4523\n",
      "Epoch 32/50\n",
      "265/265 [==============================] - 790s 3s/step - loss: 0.5125 - val_loss: 0.5594\n",
      "Epoch 33/50\n",
      "265/265 [==============================] - 794s 3s/step - loss: 0.5055 - val_loss: 0.4436\n",
      "Epoch 34/50\n",
      "265/265 [==============================] - 793s 3s/step - loss: 0.5138 - val_loss: 0.4139\n",
      "Epoch 35/50\n",
      "265/265 [==============================] - 790s 3s/step - loss: 0.5007 - val_loss: 0.4487\n",
      "Epoch 36/50\n",
      "265/265 [==============================] - 789s 3s/step - loss: 0.4751 - val_loss: 0.4266\n",
      "Epoch 37/50\n",
      "265/265 [==============================] - 792s 3s/step - loss: 0.4954 - val_loss: 0.4539\n",
      "Epoch 38/50\n",
      "265/265 [==============================] - 789s 3s/step - loss: 0.4603 - val_loss: 0.4523\n",
      "Epoch 39/50\n",
      "265/265 [==============================] - 791s 3s/step - loss: 0.4570 - val_loss: 0.4548\n",
      "Epoch 40/50\n",
      "265/265 [==============================] - 795s 3s/step - loss: 0.4624 - val_loss: 0.3731\n",
      "Epoch 41/50\n",
      "265/265 [==============================] - 459s 2s/step - loss: 0.4402 - val_loss: 0.3978\n",
      "Epoch 42/50\n",
      "265/265 [==============================] - 736s 3s/step - loss: 0.4424 - val_loss: 0.3702\n",
      "Epoch 43/50\n",
      "265/265 [==============================] - 790s 3s/step - loss: 0.4285 - val_loss: 0.3828\n",
      "Epoch 44/50\n",
      "265/265 [==============================] - 793s 3s/step - loss: 0.4194 - val_loss: 0.3966\n",
      "Epoch 45/50\n",
      "265/265 [==============================] - 744s 3s/step - loss: 0.4293 - val_loss: 0.3750\n",
      "Epoch 46/50\n",
      "265/265 [==============================] - 790s 3s/step - loss: 0.4060 - val_loss: 0.3958\n",
      "Epoch 47/50\n",
      "265/265 [==============================] - 788s 3s/step - loss: 0.4156 - val_loss: 0.4041\n",
      "Epoch 48/50\n",
      "265/265 [==============================] - 788s 3s/step - loss: 0.4026 - val_loss: 0.4159\n",
      "Epoch 49/50\n",
      "265/265 [==============================] - 787s 3s/step - loss: 0.3958 - val_loss: 0.4171\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'logs/test_vit_big_aug5'\n",
    "history = vit_classifier.fit(dt,validation_data=dv, epochs = 50,\n",
    "                    callbacks = [savebest,keras.callbacks.TensorBoard(log_dir=log_dir)],\n",
    "                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515270d2",
   "metadata": {},
   "source": [
    "## Test a pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c1e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_keras import vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3452766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valla\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\vit_keras\\utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "model_pretrained = vit.vit_l16(\n",
    "    image_size=image_size,\n",
    "    activation='linear',\n",
    "    pretrained=True,\n",
    "    include_top=False,\n",
    "    pretrained_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82aa65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input((224,224,3))\n",
    "x = model_pretrained(inputs)\n",
    "out = mlp(x,[720,360],0.6)\n",
    "model_full = keras.Model(inputs=inputs, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e476267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vit-l16 (Functional)         (None, 1024)              303301632 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 720)               738000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 360)               259560    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 360)               0         \n",
      "=================================================================\n",
      "Total params: 304,299,192\n",
      "Trainable params: 997,560\n",
      "Non-trainable params: 303,301,632\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pretrained.trainable = False\n",
    "model_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b21e5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_opener_pre(name):\n",
    "    img = tf.io.decode_png(tf.io.read_file(name))\n",
    "    X = tf.image.resize(img,(224,224))\n",
    "    Xn = tf.image.per_image_standardization(X)\n",
    "    \n",
    "    part = tf.strings.split(name,os.sep)\n",
    "    fname = part[4]\n",
    "    fpart = tf.strings.split(fname,'_')\n",
    "    if len(fpart)<2:\n",
    "        y = -1\n",
    "    else:\n",
    "        el_label = fpart[1]\n",
    "        y = -1\n",
    "        for idx, label in enumerate(label_name):\n",
    "            if label == el_label:\n",
    "                y = idx\n",
    "    data = (Xn,y)\n",
    "    return data\n",
    "def input_pipeline_pre(ds, augmentation = False):\n",
    "    ds = ds.shuffle(10000)\n",
    "    ds = ds.map(data_opener_pre)\n",
    "    #filter out the unlabeled elements\n",
    "    ds = ds.filter(lambda X,y: y>=0)\n",
    "    if augmentation:\n",
    "        ds = ds.map(data_aug)\n",
    "    ds = ds.batch(16)\n",
    "    ds = ds.prefetch(10)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7d63077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtp = tf.data.Dataset.from_tensor_slices(train)\n",
    "dvp = tf.data.Dataset.from_tensor_slices(val)\n",
    "\n",
    "dtp = input_pipeline_pre(dtp,augmentation = True)\n",
    "dvp = input_pipeline_pre(dvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81e02d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full.compile(optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay),\n",
    "                   loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4e7e82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "530/530 [==============================] - 5575s 10s/step - loss: 4.2004 - val_loss: 2.4265\n",
      "Epoch 2/50\n",
      "530/530 [==============================] - 1898s 4s/step - loss: 4.0179 - val_loss: 1.9667\n",
      "Epoch 3/50\n",
      "530/530 [==============================] - 1890s 4s/step - loss: 3.8928 - val_loss: 1.7645\n",
      "Epoch 4/50\n",
      "530/530 [==============================] - 1932s 4s/step - loss: 3.9110 - val_loss: 1.7525\n",
      "Epoch 5/50\n",
      "530/530 [==============================] - 2037s 4s/step - loss: 3.8685 - val_loss: 1.6967\n",
      "Epoch 6/50\n",
      "530/530 [==============================] - 1965s 4s/step - loss: 3.8645 - val_loss: 1.6894\n",
      "Epoch 7/50\n",
      "274/530 [==============>...............] - ETA: 5:08:53 - loss: 3.8693"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  NewRandomAccessFile failed to Create/Open: R:\\3.Masters_projects\\2021_Dominic_Rebindaine\\ROI\\20211124_Oocystis_6mm_1\\20211124_Oocystis_6mm_1_185\\38_45_2.png : The network path was not found.\r\n; Unknown error\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n  (1) Unknown:  NewRandomAccessFile failed to Create/Open: R:\\3.Masters_projects\\2021_Dominic_Rebindaine\\ROI\\20211124_Oocystis_6mm_1\\20211124_Oocystis_6mm_1_185\\38_45_2.png : The network path was not found.\r\n; Unknown error\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_172313]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8416/3140127636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'logs/test_vit_pretrained_aug5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model_full.fit(dtp,validation_data=dvp, epochs = 50,\n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msavebest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     use_multiprocessing=True)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  NewRandomAccessFile failed to Create/Open: R:\\3.Masters_projects\\2021_Dominic_Rebindaine\\ROI\\20211124_Oocystis_6mm_1\\20211124_Oocystis_6mm_1_185\\38_45_2.png : The network path was not found.\r\n; Unknown error\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n  (1) Unknown:  NewRandomAccessFile failed to Create/Open: R:\\3.Masters_projects\\2021_Dominic_Rebindaine\\ROI\\20211124_Oocystis_6mm_1\\20211124_Oocystis_6mm_1_185\\38_45_2.png : The network path was not found.\r\n; Unknown error\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_172313]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'logs/test_vit_pretrained_aug5'\n",
    "history = model_full.fit(dtp,validation_data=dvp, epochs = 50,\n",
    "                    callbacks = [savebest,keras.callbacks.TensorBoard(log_dir=log_dir)],\n",
    "                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda85a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
